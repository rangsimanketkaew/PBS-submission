#!/bin/csh

# NWChem Interactive Job Submission on TAIWANIA cluster, NCHC, Taiwan.
#
# Updated 2018.10.08  Rangsiman Ketkaew  rangsiman1993@gmail.com
# https://github.com/rangsimanketkaew/QM-on-TAIWANIA/

###############################################################################
set NWCHEM_VER            = "6.8.0"
set NWCHEM_TOP            = "/pkg/nwchem/Casper/i18gcc6/nwchem-6.8.1-fixmrcc"
set NWCHEM_TOP_CASPER     = "$NWCHEM_TOP"
set NWCHEM_TOP_MPIPR      = "/pkg/nwchem/MPI-PR/i18gcc6/nwchem-6.8.1-fixmrcc"
set NWCHEM_TOP_CASPER_GPU = "/pkg/nwchem/Casper/i18gcc6/nwchem-6.8.1-fixcuda"
set NWCHEM_TOP_MPIPR_GPU  = "NOTAVAIALBLE"
set NWCHEM_TOP_GPU        = "$NWCHEM_TOP_CASPER_GPU"
set NWCHEM_TARGET         = "LINUX64"
###############################################################################
set NWCHEM_RESRC          = "/pkg/nwchem/etc/default.nwchemrc"
set NWCHEM_CASLIB         = "/pkg/nwchem/exp/i18/deps/lib"
###############################################################################
set CLEANSRC              = "$HOME/.nwchem-clean-up"
set CLEAN_CASPER          = "$CLEANSRC/cleanup-devshm.sh"
set CLEAN_MPIPR           = "$CLEANSRC/cleanup-cmx.sh"
###############################################################################
set PROJ_ID_FILE          = "$HOME/.proj_id"
###############################################################################

begin_program:

onintr int

set OUTPUT_ARG2  = 0
set GPU          = 0
set USEGPU       = 0
set ARMCI        = 0
set CASPER       = 0
set CASPER_GPU   = 0
set MPIPR        = 0
set MPIPR_GPU    = 0

echo ""
echo "     ###########################################################"
echo "    ###   NWChem $NWCHEM_VER Interactive Submission on TAIWANIA   ###"
echo "   ###########################################################"
echo ""

#############################################
# Check input arguments.
#############################################

# Total arguments
set ARGV_ORDER = "$#argv"

if ($ARGV_ORDER == 0) then
  echo "   Usage: subnwchem input[.nw] [output[.out]] [gpu | casper | mpipr] [-help]"
  echo ""
  exit 0
else if ("$1" == "-help" || "$1" == "--help" || "$1" == "-h" || "$1" == "help" ) then
  goto help
endif

if ($ARGV_ORDER == 1) then
  set INPUT_ARG1 = "$1"
  set OUTPUT_ARG2 = 0
  goto nwchem_def
endif

if ($ARGV_ORDER >1) then
  set INPUT_ARG1 = "$1"
  @ i = 2
  while ($i <= $ARGV_ORDER)
#############################################
# Check if the 2nd argument is special request 
# (help, gpu, casper, and mpipr).
#############################################
    if ("$i" == "2") then
      set SPEC_RE = `echo $argv[2] | grep -Eiwc 'help|gpu|casper|mpipr|mpi-pr'`
      if ($SPEC_RE != "1") then
        set OUTPUT_ARG2 = "$argv[2]"
      else
        goto check_special_argv
      endif
# Check other arguments
    else
check_special_argv:
      set ARGV = $argv[$i]
      if (`echo $ARGV|grep -Eiwc 'help'` == "1") then
        goto help
      else if (`echo $ARGV|grep -Eiwc 'gpu'` == "1") then
        set USEGPU = 1
      else if (`echo $ARGV|grep -Eiwc 'casper'` == "1") then
        set ARMCI = 1
        set CASPER = 1
      else if (`echo $ARGV|grep -Eiwc 'mpipr|mpi-pr'` == "1") then
        set ARMCI = 1
        set MPIPR = 1
      else
        echo "Error: Invalid command $ARGV"
        echo -n "######### Enter to start help page. #########" 
        set HELP = "$<"
        clear
        goto help
        exit 1
      endif
    endif
    @ i ++
  end
endif

#############################################
# Check if GPU and/or ARMCI are requested.
#############################################

if ($USEGPU == 1) then
  echo "Enabled NWChem/CUDA"
  if ($ARMCI == 1) then
    goto armci_check
  else
# ARMCU is not used
    set NWCHEM_TOP = "$NWCHEM_TOP_GPU"
# to define $NWCHEM_RUNTIME
    set GPU = 1
    goto start_program
  endif
else
  if ($ARMCI == 1) then
    goto armci_check
  else
    set CASPER = 0
    set MPIPR = 0
    goto nwchem_def
  endif
endif 

#############################################
# Check if Casper or MPI-PR will be used.
#############################################

armci_check:
if ( $CASPER == $MPIPR ) then
  echo "Error: Conflict in ARM-CI. Use either Casper or MPI-PR."
  exit 1
endif

if ("null$CASPER" == "null1") then
  set NWCHEM_TOP = "$NWCHEM_TOP_CASPER"
  set CASPER = 1
  set MPIPR = 0
  echo "Enabled ARMCI Casper"
  if ($USEGPU == 1) then
# Set CASPER_GPU = 1 to define $NWCHEM_RUNTIME
    set CASPER_GPU = 1
    set NWCHEM_TOP = "$NWCHEM_TOP_CASPER_GPU"
    goto start_program
  endif
  goto start_program
else if ("null$MPIPR" == "null1") then
  set NWCHEM_TOP = "$NWCHEM_TOP_MPIPR"
  set CASPER = 0
  set MPIPR = 1
  echo "Enabled ARMCI MPI-PR"
  if ($USEGPU == 1) then
# Disable NWChem GPU/MPI-PR
    echo "Error: NWChem with GPU & MPI-PR is not available."
# Set MPIPR_GPU = 1 to define $NWCHEM_RUNTIME
    set MPIPR_GPU = 1
    set NWCHEM_TOP = "$NWCHEM_TOP_MPIPR_GPU"
    goto start_program
  endif
  goto start_program
endif

#############################################
# If no special method request, use default
# setting.
#############################################

nwchem_def:
set CASPER = 0
set MPIPR = 0

#############################################
# Start program: user is asked to fill the
# necessary information for creating PBS job.
#############################################

start_program:
if (! -e $NWCHEM_TOP) then
  echo 'Error: Unable to locate NWCHEM_TOP directory, $NWCHEM_TOP.'
  echo 'Please set the suitable path of $NWCHEM_TOP at the beginning lines of this program source code'
  exit 1
else
  set NWCHEM_EXE = "$NWCHEM_TOP/bin/$NWCHEM_TARGET/nwchem"
endif

if (! -f $NWCHEM_EXE) then
  echo 'Error: Unable to locate "nwchem" executable in $NWCHEM_TOP/bin/$NWCHEM_TARGET/ directory.'
  exit 1
endif

#############################################
# Determine Input file.
#############################################

pushd $HOME >& /dev/null
set PWDHOME = `pwd`
popd >& /dev/null
set noglob
set FULLPATH = `pwd | sed -e "s,$PWDHOME,~,"`
unset noglob

#search_input:
#set DEFAULTINPUT = "$FULLPATH/nwchem.nw"
#echo -n "Enter input file [$DEFAULTINPUT]: "
#set JOBINPUT = "$<"
#if ("null$JOBINPUT" == "null") then
#  set JOBINPUT = "$DEFAULTINPUT"
#---------------------------------------------------
##else
##  set JOBINPUT_TYPE = `printf $JOBINPUT | tail -c 3`
##  if ("null$JOBINPUT_TYPE" != "null.nw") then
##    echo "Error: NWChem input file must be *.nw"
##    goto search_input
##  else
##    set INPUTFILE = "$JOBINPUT"
##  endif
#endif
#

set JOBINPUT = "$INPUT_ARG1"
set INPUTFILE = "$FULLPATH/$JOBINPUT"
if (-f $INPUTFILE) then
   set JOBINPUT = "$INPUTFILE"
 else if (-f $INPUTFILE.nw) then
   set JOBINPUT = "$INPUTFILE.nw"
endif
#
if (! -f $JOBINPUT) then
  echo "Error: Failed to locate input file "$JOBINPUT""
  exit 1
endif

#############################################
# Define name of output file.
#############################################

if ($OUTPUT_ARG2 != 0) then
  set OUTPUTFILE = "$OUTPUT_ARG2"
  set OUTPUTNAME = `basename $OUTPUTFILE .out`
  set OUTPUTFILE = "$OUTPUTNAME".out
  set JOBOUTPUT = "$FULLPATH/$OUTPUTFILE"
  goto ask_gpu
endif

set noglob
set JOBOUTPUT  = `basename $JOBINPUT .nw`.out
unset noglob
set DEFAULTOUTPUT = "$JOBOUTPUT"

if (! -e $JOBOUTPUT) then
  set OUTPUTNAME = `basename $JOBINPUT .nw`.out
else
  @ i = 1
  while (-e $JOBOUTPUT)
    echo "@  $JOBOUTPUT  already exists."
    set noglob
    set JOBOUTPUT = `basename $JOBINPUT .nw`.$i.out
    set OUTPUTNAME = `basename $JOBINPUT .nw`.$i.out
    unset noglob
    @ i ++
  end
  set DEFAULTOUTPUT = "$JOBOUTPUT"
endif

#
echo -n "Enter output file [$OUTPUTNAME]: "
set OUTPUTFILE = "$<"
if ("null$OUTPUTFILE" != "null") then
  set noglob
  set JOBOUTPUT = "$FULLPATH/$OUTPUTFILE"
# If user-defined output name is not in .out,
# set foo to foo.out
  set JOBOUTPUT_TYPE = `printf $JOBOUTPUT | tail -c 4`
  if ("null$JOBOUTPUT_TYPE" != "null.out") then
    set JOBOUTPUT = "$FULLPATH/$OUTPUTFILE".out
  endif
  unset noglob
else
  set JOBOUTPUT = "$FULLPATH/$DEFAULTOUTPUT"
endif

#############################################
# Define Computing Resource for GPU queue.
#############################################

ask_gpu:
if ($USEGPU == 1) then
  echo -n "Number of GPU cores [1]: "
  set JOBGPU = "$<"
  if ("null$JOBGPU" == "null") then
   set JOBGPU = 1
  else if ($JOBGPU >= 33) then
   echo "Error: Maximum GPU is 32"
   goto ask_gpu
  else if ($JOBGPU <= 0) then
   echo "Error: Enter only positive integer"
   goto ask_gpu
  endif
endif

# If GPU/CUDA is enabled, skip CPU queue
if ($USEGPU == 1) then
  set TOTALGPU = "$JOBGPU"
  goto gpu_queue
endif

#############################################
# Define Computing Resource for CPU queue.
#############################################

  ask_node:
  echo -n "Number of Compute node [1]: "
  set JOBNODE = "$<"
  if ("null$JOBNODE" == "null") then
   set JOBNODE = 1
  else if ($JOBNODE >= 601) then
   echo "Error: Maximum node is 600"
   goto ask_node
  else if ($JOBNODE <= 0) then
   echo "Error: Enter only positive integer"
   goto ask_node
  endif
#
  ask_cpu:
  echo -n "Number of CPU cores [40]: "
  set JOBCPU = "$<"
  if ("null$JOBCPU" == "null") then
   set JOBCPU = 40
  else if ($JOBCPU >= 41) then
   echo "Error: Maximum CPU cores/node is 40"
   goto ask_cpu
  else if ($JOBCPU <= 0) then
   echo "Error: Enter only positive integer"
   goto ask_cpu
  endif

#############################################
# Number of MPI process is set to = $JOPCPU.
# Each MPI process uses 1 OMP Thread.
# To configure these settings, you must 
# uncomment following lines first.
#############################################

  #ask_mpi:
  #echo -n "Number of MPI process [$JOBCPU]: "
  #set JOBMPI = "$<"
  #if ("null$JOBMPI" == "null") then
   set JOBMPI = $JOBCPU
  #else if ($JOBMPI >= 41) then
  # echo "Error: Maximum MPI process/node is 40"
  # goto ask_mpi
  #else if ($JOBMPI <= 0) then
  # echo "Error: Enter only positive integer"
  # goto ask_mpi
  #endif
#
  #ask_omp:
  #echo -n "Number of OMP Threads [1]: "
  #set JOBOMP = "$<"
  #if ("null$JOBOMP" == "null") then
   set JOBOMP = 1
  #else if ($JOBOMP >= 41) then
  # echo "Error: Maximum OpenMP Threads/node is 40"
  # goto ask_omp
  #else if ($JOBOMP <= 0) then
  # echo "Error: Enter only positive integer"
  # goto ask_omp
  #endif

set TOTALGPU = "-"

#############################################
# Calculate total number of MPI process.
#############################################

@ TOTALMPI = ($JOBNODE * $JOBMPI)
if ( $CASPER != 0 || $MPIPR != 0 ) then
  if ($TOTALMPI == 1) then
    echo "Error: ARMCI Casper are MPI-PR require MPI process > 1"
    goto ask_node
  endif
endif

#############################################
# Search optimal CPU queue and wall-time.
#############################################

cpu_queue:
  if ($TOTALMPI == 1) then
   set CPUQUEUE = "serial"
  else if ($TOTALMPI <= 40) then
   set CPUQUEUE = "cf40"
  else if ($TOTALMPI <= 160) then
   set CPUQUEUE = "cf160"
  else if ($TOTALMPI <= 400) then
   set CPUQUEUE = "ct400"
  else if ($TOTALMPI <= 800) then
   set CPUQUEUE = "ct800"
  else if ($TOTALMPI <= 1200) then
   set CPUQUEUE = "cf1200"
  else if ($TOTALMPI <= 2000) then
   set CPUQUEUE = "ct2k"
  else if ($TOTALMPI <= 6000) then
   set CPUQUEUE = "ct6k"
  else if ($TOTALMPI <= 8000) then
   set CPUQUEUE = "ct8k"
  else if ($TOTALMPI <= 22400) then
   set CPUQUEUE = "ct22400"
  endif

check_cpu_queue:
  echo -n "Job Queue [optimal queue is $CPUQUEUE]: "
  set CHECKQUEUE = "$<"
  if ("null$CHECKQUEUE" == "null") then
    set JOBQUEUE = "$CPUQUEUE"
  else if ("null$CHECKQUEUE" == "nullserial") then
    set JOBQUEUE = serial
    goto sum_cpu
  else if ("null$CHECKQUEUE" == "nullctest") then
    set JOBQUEUE = ctest
  else
#
    set Q_CPU_LIST = ( serial ctest cf40 cf160 ct400 ct800 cf1200 ct2k ct6k ct8k ct22400 )
    @ i = 1
    while ($i <= $#Q_CPU_LIST)
      if ("$CHECKQUEUE" == "$Q_CPU_LIST[$i]") then
        set TESTQUEUE = 1
        break
      else
        set TESTQUEUE = 0
      endif
      @ i ++
    end
      if ($TESTQUEUE != 1) then
        echo "Error: queue '$CHECKQUEUE' not found."
        echo "Available CPU queues are: $Q_CPU_LIST"
        goto check_cpu_queue
      else
        set JOBQUEUE = "$CHECKQUEUE"
      endif
  endif

# Check if requested MPI processes match ctest policy
if ($JOBQUEUE == ctest) then
  if ($TOTALMPI >= 81) then
    echo "Error: total MPI processes you requested, $TOTALMPI processes, violates policy of ctest queue."
    goto check_cpu_queue
  endif
endif

# If CPU queue is used, disabled GPU
sub_cpu:
  set JOBGPU = "-" 
  set SETGPU = ""
  goto job_setting

#############################################
# Search optimal GPU queue and wall-time.
# Previously, $TOTALGPU is set to $JOBCPU.
#############################################

gpu_queue:
  if ($TOTALGPU <= 4) then
   set GPUQUEUE = "gp4"
  else if ($TOTALGPU <= 16) then
   set GPUQUEUE = "gp16"
  else if ($TOTALGPU <= 32) then
   set GPUQUEUE = "gp32"
  endif

#############################################
# Number of Compute node that user can 
# request depends on GPU job queue.
#############################################

# gp4
  if ($GPUQUEUE == gp4) then
    set JOBNODE = 1
# gp16
  else if ($GPUQUEUE == gp16) then
    ask_node_for_gpu:
    echo -n "Number of Compute node [2]: "
    set JOBNODE = "$<"
    if ("null$JOBNODE" == "null") then
     set JOBNODE = 1
    else if ($JOBNODE >= 5) then
     echo "Error: Maximum node is 4"
     goto ask_node_for_gpu
    else if ($JOBNODE <= 0) then
     echo "Error: Enter only positive integer"
     goto ask_node_for_gpu
    else if ($JOBNODE <= 1) then
     echo "Error: Minimum node is 2"
     goto ask_node_for_gpu
    endif
# gp32
  else if ($GPUQUEUE == gp32) then
    ask_node_for_gpu:
    echo -n "Number of Compute node [2]: "
    set JOBNODE = "$<"
    if ("null$JOBNODE" == "null") then
     set JOBNODE = 1
    else if ($JOBNODE >= 9) then
     echo "Error: Maximum node is 8"
     goto ask_node_for_gpu
    else if ($JOBNODE <= 0) then
     echo "Error: Enter only positive integer"
     goto ask_node_for_gpu
    else if ($JOBNODE <= 4) then
     echo "Error: Minimum node is 5"
     goto ask_node_for_gpu
    endif
  endif

  ask_cpu_for_gpu:
  echo -n "Number of CPU cores [40]: "
  set JOBCPU = "$<"
  if ("null$JOBCPU" == "null") then
   set JOBCPU = 40
  else if ($JOBCPU >= 41) then
   echo "Error: Maximum CPU cores/node is 40"
   goto ask_cpu_for_gpu
  else if ($JOBCPU <= 0) then
   echo "Error: Enter only positive integer"
   goto ask_cpu_for_gpu
  endif
## Number of MPI process is set to $JOBCPU.
  set JOBMPI = $JOBCPU
## OMP_NUM_THREADS is set to 1 (per MPI).
  set JOBOMP = 1

#############################################
# Determine total number of MPI process.
#############################################

@ TOTALMPI = ($JOBNODE * $JOBMPI)
if ( $CASPER != 0 || $MPIPR != 0 ) then
  if ($TOTALMPI == 1) then
    echo "Error: ARMCI Casper and MPI-PR require MPI process > 1"
    goto ask_node
  endif
endif

check_gpu_queue:
  echo -n "Job Queue [optimal GPU queue is $GPUQUEUE]: "
  set CHECKQUEUE = "$<"
  if ("null$CHECKQUEUE" == "null") then
    set JOBQUEUE = "$GPUQUEUE"
  else if ("null$CHECKQUEUE" == "nullgtest") then
# 
    ask_gpu_for_gtest:
    if ($USEGPU == 1) then
      echo -n "Number of GPU cores [1]: "
      set JOBGPU = "$<"
      if ("null$JOBGPU" == "null") then
        set JOBGPU = 1
      else if ($JOBGPU >= 9) then
        echo "Error: Maximum GPU is 8"
        goto ask_gpu_for_gtest
      else if ($JOBGPU <= 0) then
        echo "Error: Enter only positive integer"
        goto ask_gpu_for_gtest
      endif
    endif
#
     set TOTALGPU = $JOBGPU
# determine optimal number of cpu
    ask_cpu_for_gtest:
    echo -n "Number of CPU cores [4]: "
    set JOBCPU = "$<"
    if ("null$JOBCPU" == "null") then
      set JOBCPU = 4
    else if ($JOBCPU >= 9) then
      echo "Error: Maximum CPU cores/node is 8"
      goto ask_cpu_for_gtest
    else if ($JOBCPU <= 0) then
      echo "Error: Enter only positive integer"
      goto ask_cpu_for_gtest
    endif
# 
    set JOBQUEUE = gtest
    set JOBNODE = 1
    set JOBMPI = $JOBCPU
    set JOBOMP = 1
  else
#
    set Q_GPU_LIST = ( gtest gp4 gp16 gp32 )
    @ i = 1
    while ($i <= $#Q_GPU_LIST)
      if ("$CHECKQUEUE" == "$Q_GPU_LIST[$i]") then
        set TESTQUEUE = 1
        break
      else
        set TESTQUEUE = 0
      endif
      @ i ++
    end
      if ($TESTQUEUE != 1) then
        echo "Error: queue '$CHECKQUEUE' not found."
        echo "Available GPU queues are: $Q_GPU_LIST"
        goto check_gpu_queue
      else
        set JOBQUEUE = "$CHECKQUEUE"
      endif
  endif

# Define 'ngpus' for PBS script
  set SETGPU = ":ngpus=$TOTALGPU" 

#############################################
# Define job name & standard error & output 
# and check project ID.
#############################################

job_setting:
set JOBNAME = `basename $JOBINPUT .nw`
set JOBSTDERR = `basename $JOBOUTPUT .out`.stderr
set JOBSTDOUT = `basename $JOBOUTPUT .out`.stdout

#############################################
# Set NWChem runtime and determine clean-up 
# file for Casper and MPI-PR methods.
#############################################

if ("null$GPU" == "null1") then
  set NWCHEM_RUNTIME = GPU
  set NWCHEM_TYPE = "GPU"
else if ("null$CASPER_GPU" == "null1") then
  set NWCHEM_RUNTIME = CASPER_GPU
  set NWCHEM_TYPE = "ARMCI: Casper & GPU"
else if ("null$MPIPR_GPU" == "null1") then
  set NWCHEM_RUNTIME = MPIPR_GPU
  set NWCHEM_TYPE = "ARMCI: MPI-PR & GPU"
else if ("null$CASPER" == "null1") then
  set NWCHEM_RUNTIME = CASPER
  set NWCHEM_TYPE = "ARMCI: Casper"
else if ("null$MPIPR" == "null1") then
  set NWCHEM_RUNTIME = MPIPR
  set NWCHEM_TYPE = "ARMCI: MPI-PR"
else
  set NWCHEM_RUNTIME = NORM
  set NWCHEM_TYPE = "No ARMCI"
endif

#############################################
# Check if $CLEANSRC exists
#############################################

if ( ! -e $CLEANSRC ) then
  mkdir -p $CLEANSRC
else
  goto job_proj_id
endif

#############################################
# Create cleanup-devshm.sh for Casper
#############################################

if ( ! -f $CLEAN_CASPER ) then
cat <<EOF > $CLEAN_CASPER
#!/bin/bash

######### cleanup-devshm.sh was created by subnwchem ##########
# This script will be used to remove garbage on compute nodes #
# before & after running NWChem on TAIWANIA cluster.          #
###############################################################

MPIPR_JUNK_PREFIX="/dev/shm/*cmx"

GARBAGE=\`ls -1 \${MPIPR_JUNK_PREFIX}* 2>/dev/null\`
if [ "\$GARBAGE" != "" ]; then
  echo "Cleaning up \$GARBAGE at \$HOSTNAME"
  rm -f \$GARBAGE
fi

PSM2_JUNK_PREFIX="/dev/shm/psm2_shm"

GARBAGE=\`ls -1 \${PSM2_JUNK_PREFIX}* 2>/dev/null\`
if [ "\$GARBAGE" != "" ]; then
  echo "Cleaning up \$GARBAGE at \$HOSTNAME"
  rm -f \$GARBAGE
fi

EOF
endif

#############################################
# Create cleanup-cmx.sh for MPI-PR
#############################################

if ( ! -f $CLEAN_MPIPR ) then
cat <<EOF > $CLEAN_MPIPR
#!/bin/bash

########### cleanup-cmx.sh was created by subnwchem ###########
# This script will be used to remove garbage on compute nodes #
# before & after running NWChem on TAIWANIA cluster.          #
###############################################################

MPIPR_JUNK_PREFIX="/dev/shm/*cmx"

GARBAGE=\`ls -1 \${MPIPR_JUNK_PREFIX}* 2>/dev/null\`
if [ "\$GARBAGE" != "" ]; then
  echo "Cleaning up \$GARBAGE at \$HOSTNAME"
  rm -f \$GARBAGE
fi

EOF
endif

#############################################
# Determine project id
#############################################

job_proj_id:
set LISTID = ( `get_su_balance | awk -F, '{print $2}' | xargs` )

if ( "$LISTID" == "" ) then
  echo "Error: No available Project ID."
  exit 1
else if ( $#LISTID == 1 ) then
  set PROJ_ID = "$LISTID[1]"
  goto job_info
endif

if ( -f $PROJ_ID_FILE ) then
  set PROJID_1 = `head -1 $PROJ_ID_FILE`
  if ( `get_su_balance | grep -wc "$PROJID_1"` == 0 ) then
    echo "Error: Project ID specified in first line of $PROJ_ID_FILE is not correct."
    exit 1
  endif
  set PROJ_ID = "$PROJID_1"
  goto job_info
endif

set BALANCE = ( `get_su_balance | awk -F, '{print $1}' | xargs` )
echo ""
echo " Your available Project ID & SU Balance:"
@ i = 1
while ( $i <= $#LISTID )
echo " [$i]  $LISTID[$i]  $BALANCE[$i]"
set PROJ_ID = "$LISTID[1]"
@ i++
end
echo ""

ask_id_choice:
echo -n "Enter Project ID [1]: "
set PROJINP = "$<"

if ( "null$PROJINP" == "null" ) then
  set PROJ_ID = "$LISTID[1]"
  goto job_info
endif

if ( `echo $PROJINP | grep -c '[a-z][A-Z]*'` == 1 ) then
  echo "Error: Please assign choice as positive integer."
  goto ask_id_choice
endif

if ( $PROJINP > $#LISTID || $PROJINP <= 0 ) then
  echo "Error: Choice you selected is out of range."
  goto ask_id_choice
else
  set PROJ_ID = "$LISTID[$PROJINP]"
endif

job_info:

#############################################
# Show job information before submit
#############################################

  echo ""
  echo " =========================== $ Job Information $ =========================="
  echo " Run on `date` by `whoami`"
  echo ""
  echo " NWChem runtime         = $NWCHEM_VER - $NWCHEM_TYPE"
  echo " NWChem executable      = $NWCHEM_EXE"
  echo ""
  echo " Input file             = $JOBINPUT"
  echo " Output file            = $JOBOUTPUT"
  echo ""
  echo " Compute node           = $JOBNODE"
  echo " CPU cores per node     = $JOBCPU"
  echo " GPU accelerator        = $TOTALGPU"
  echo " MPI process per node   = $JOBMPI"
  echo " OMP Threads per node   = $JOBOMP"
  echo " Total MPI process      = $JOBNODE x $JOBMPI = $TOTALMPI processes"
  echo ""
  echo " Job Name               = $JOBNAME"
  echo " Job Queue              = $JOBQUEUE"
  echo " Std Error              = $FULLPATH/$JOBSTDERR"
  echo " Std Output             = $FULLPATH/$JOBSTDOUT"
  echo " Project ID             = $PROJ_ID"
  echo " =========================================================================="
  echo ""

echo -n "Submit your job now ? [yes]: "
set CONFIRM = "$<"

if ("null$CONFIRM" == "null" || "null$CONFIRM" == "nully" || "null$CONFIRM" == "nullyes") then
else
  echo "Error: PBS submission aborted !"
re_submit:
  echo -n "Do you want to re-submit ? [no]: "
  set RESUBMIT = "$<"
    if ($RESUBMIT == "" || $RESUBMIT == "n" || $RESUBMIT == "no") then
      exit 1
    else if ($RESUBMIT == "y" || $RESUBMIT == "yes") then
      goto begin_program
    else
      echo "Error: [y/n] ?"
      goto re_submit
    endif
endif

#############################################
# Creat PBS script and write all parameter
# and configuration settings.
#############################################

set JOB_SCRIPT = `dirname $JOBOUTPUT`/submit.NWChem.`basename $JOBOUTPUT .out`.sh

cat <<EOF > $JOB_SCRIPT
#!/bin/bash
#PBS -l select=${JOBNODE}:ncpus=${JOBCPU}:mpiprocs=${JOBMPI}:ompthreads=${JOBOMP}$SETGPU
#PBS -q $JOBQUEUE
#PBS -N $JOBNAME
#PBS -e $JOBSTDERR
#PBS -o $JOBSTDOUT
#PBS -P $PROJ_ID

################################################################
#### This PBS Pro script was generated by subnwchem program ####
################################################################

module purge
module load intel/2018_u1 cuda/8.0.61 gcc/6.3.0

cd \$PBS_O_WORKDIR

ulimit -c 0
ulimit -s unlimited

export SCRATCH_DIR=/work1/$USER/SCRATCH/nwchem/nwchem.pbs\${PBS_JOBID/\.srvc1/}
if [ ! -d \$SCRATCH_DIR ]; then mkdir -p \$SCRATCH_DIR; fi

export I_MPI_FABRICS=shm:tmi
export I_MPI_PIN_DOMAIN=omp
export I_MPI_HYDRA_BRANCH_COUNT=-1
export I_MPI_HYDRA_PMI_CONNECT=alltoall

export MPI_ROOT=\$I_MPI_ROOT/intel64
export MPICC=\$MPI_ROOT/bin/mpiicc
export MPICXX=\$MPI_ROOT/bin/mpiicpc
export MPIFC=\$MPI_ROOT/bin/mpiifort

export NWCHEM_EXE=$NWCHEM_EXE
export NWCHEM_TARGET=$NWCHEM_TARGET
export NWCHEM_RESRC=$NWCHEM_RESRC
export NWCHEM_CASLIB=$NWCHEM_CASLIB

if [ ! -f ~/.nwchemrc ]; then ln -s \$NWCHEM_RESRC ~/.nwchemrc; fi

export MACHLIST=\$PBS_O_WORKDIR/nodelist.\${PBS_JOBID/\.srvc1/}

cat \$PBS_NODEFILE | sed -e 's/.*/&\.nchc\.opa/' > \$MACHLIST
export CASCLEAN="for RUNNODE in \`uniq \$MACHLIST\`; ssh \$RUNNODE $CLEANSRC/cleanup-devshm.sh; done"
export MPIPRCLEAN="for RUNNODE in \`uniq \$MACHLIST\`; ssh \$RUNNODE $CLEANSRC/cleanup-cmx.sh; done"

EOF

#---------------------------------------

if ("null$NWCHEM_RUNTIME" == "nullGPU") then
cat <<EOF >> $JOB_SCRIPT

########################
\$CASCLEAN
########################

mpiexec.hydra -PSM2 -n $TOTALMPI \$NWCHEM_EXE \
$JOBINPUT > $JOBOUTPUT

########################
\$CASCLEAN
########################

EOF

#---------------------------------------

else if ("null$NWCHEM_RUNTIME" == "nullCASPER_GPU" || "null$NWCHEM_RUNTIME" == "nullCASPER") then
cat <<EOF >> $JOB_SCRIPT
export ARMCI_NETWORK=ARMCI

########################
\$CASCLEAN
########################

mpiexec.hydra -PSM2 -n $TOTALMPI -genv CSP_NG 1 -genv LD_PRELOAD \$NWCHEM_CASLIB/libcasper.so \
\$NWCHEM_EXE \
$JOBINPUT > \
$JOBOUTPUT

########################
\$CASCLEAN
########################

EOF

#---------------------------------------

else if ("null$NWCHEM_RUNTIME" == "nullMPIPR_GPU" || "null$NWCHEM_RUNTIME" == "nullMPIPR") then
cat <<EOF >> $JOB_SCRIPT
export ARMCI_NETWORK=MPI-PR

########################
\$MPIPRCLEAN
########################

mpiexec.hydra -PSM2 -n $TOTALMPI \$NWCHEM_EXE \
$JOBINPUT > \
$JOBOUTPUT

########################
\$MPIPRCLEAN
########################

EOF

#---------------------------------------

else if ("null$NWCHEM_RUNTIME" == "nullNORM") then
cat <<EOF >> $JOB_SCRIPT

########################
\$CASCLEAN
########################

mpiexec.hydra -PSM2 -n $TOTALMPI \$NWCHEM_EXE \
$JOBINPUT > \
$JOBOUTPUT

########################
\$CASCLEAN
########################

EOF
endif

################### End of SGE script preparation ###################

#############################################
# Submit job using 'qsub'.
#############################################

qsub $JOB_SCRIPT
#  echo "Your job has been submitted."
exit 0

int:  
 echo ""
 echo "Error: You pressed Ctrl-C  ....quit.... "
 echo ""
 exit 1

help:
clear
cat << EOF | less

                                          ---------------------------------
                                          NWChem Interactive Job Submission
                                          ---------------------------------

 NAME            subnwchem  -  Interactive PBS Professional Job Submission for NWChem $NWCHEM_VER

 SYNOPSIS        subnwchem input[.nw] [output[.out]] [gpu | casper | mpipr] [-help]

 EXAMPLE         subnwchem water                             Run water.nw and print output to water.out.

                 subnwchem water.nw                          Run water.nw and print output to water.out.

                 subnwchem water water-HF                    Run water.nw and print output to water-HF.out.

                 subnwchem H2.nw mpipr                       Request MPI-PR. \
                                                                              >  Recommended for medium & large jobs.
                 subnwchem H2.nw casper                      Request Casper. /   (Use Casper instead when MPI-PR fails)

                 subnwchem H2.nw gpu                         Request GPU for CUDA run. Job will be submitted on GPU node.
                                                             Output file is H2.out.

                 subnwchem H2.nw gpu mpipr                   [x] Not yet supported.

                 subnwchem H2.nw H2-CCSDT gpu casper         Run H2.nw with CUDA and Casper on GPU node and print output
                                                             to H2-CCSDT.out

 DESCRIPTION     subnwchem is c-shell program script designed to interactively submit NWChem job using PBS Pro scheduler.
                 Note that command line optional argument is case sensitive. Lowercase is only supported.

                 NWChem program package includes several quantum mechanical and quantum molecular dynamics simulations,
                 such as HF, DFT, TD-DFT, PW-DFT, MP2, CI, CC, TCE, MC-SCF, QM/MM, etc.
                 This NWChem can exploit ARMCI method: MPI-PR and Casper, and GPU/CUDA accelerator on GPU compute node.

                 Yet another NWChem runtimes were compiled with ARMCI methods comprise of Casper and MPI-PR models.
                 When ARMCI is enabled, one rank of all MPI ranks on each compute node will be used as ghost processes
                 dedicated to help asynchronous progress for high efficient scalable MPI calculation.
                 For example, request of 40 processes on 20 compute node each, the total MPI processes is 800.
                 If either Casper or MPI-PR is requested, 20 MPI processes are used as ghost (a.k.a. dummy) processes.
                 Hence the total actual MPI processes is 40*20 - 20 = 780. By the way, you can request N+1 MPI processors
                 to compensate the Ghost processor rather N MPI processors.

                 NWChem $NWCHEM_VER also supports General-Purpose Graphical Processing Unit (GP-GPU) and the CUDA platform.
                 GP-GPU/CUDA supports only the tensor contraction engine (TCE) module for coupled-cluster (CC) calculation.
                 Note that CUDA/MPI-PR is not now supported. Please do avoid requesting CUDA and MPI-PR simultaneously.
                 
 COMMANDS        input                 -   NWChem input file with or without .nw extension.
                 output                -   NWChem output file with or without .out extension.
                 gpu                   -   Requests GPU accelerator for CUDA to speed up calculation.
                 casper                -   Requests Casper method (conflicts with MPI-PR).
                 mpipr                 -   Requests MPI-PR method (conflicts with Casper).
                 -help                 -   Open this help.

 LIMITATION*     Maximum compute node  -   600
                 Maximum CPU cores     -   40   (per node)
                 Maximum MPI process   -   40   (per node)
                 Maximum Threads       -   40   (per node & per MPI rank)
 
 * is TAIWANIA Policy

 MORE DETAILS    NWChem official website: http://www.nwchem-sw.org 
                 NWChem official manual: https://github.com/nwchemgit/nwchem/wiki

 AUTHOR          Rangsiman Ketkaew  (MSc student)
                 E-mail: rangsiman1993@gmail.com
                 Computational Chemistry Research Unit
                 Department of Chemistry
                 Faculty of Science and Technology
                 Thammasat University, Thailand
                 Website: https://bit.ly/rangsiman1993

 Repository      https://github.com/rangsimanketkaew/QM-on-TAIWANIA

 Last updated    October 08, 2018

EOF



